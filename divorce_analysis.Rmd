---
title: "Divorce Analysis"
author: "Celeste Chen and Sarah Unbehaun"
date: "May 8, 2017"
output:
  pdf_document: default
  ---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gridExtra)
```

```{r data, include=FALSE}
load("GSSdivorce.rda")
```

### Step One: Explore and Modify Data
```{r missing, include=FALSE}
#Restrict 
GSS.divorce <- GSS.divorce[GSS.divorce$year>=1996, ]
GSS.divorce <- GSS.divorce[GSS.divorce$marital=="MARRIED" | GSS.divorce$marital=="DIVORCED" | GSS.divorce$marital=="SEPARATED", ]
GSS.divorce$marital <- factor(GSS.divorce$marital)

GSS.divorce$marital2 <- "married"
GSS.divorce$marital2 [GSS.divorce$marital == "SEPARATED"] <- "split"
GSS.divorce$marital2 [GSS.divorce$marital == "DIVORCED"] <- "split"
GSS.divorce$marital2 [is.na(GSS.divorce$marital) ==T] <- NA
GSS.divorce$marital2 <- factor(GSS.divorce$marital2)
GSSnew <- GSS.divorce[!is.na(GSS.divorce$marital2),]
summary(GSSnew$marital2)
GSSnew$sizecat <- NA
GSSnew$sizecat [GSSnew$size < 10] <- "rural"
GSSnew$sizecat [GSSnew$size >=10 & GSSnew$size <= 99] <- "small"
GSSnew$sizecat [GSSnew$size >=100 & GSSnew$size <= 999] <- "medium"
GSSnew$sizecat [GSSnew$size >=1000 & GSSnew$size <= 9999] <- "large"
GSSnew$sizecat <- factor(GSSnew$sizecat)
GSSnew$educcat <-cut(GSSnew$educ, seq(0,20,4))
```

### Step Two: Visually check distributions of variable responses

```{r visuals, echo=FALSE}
library(ggplot2)
library(plyr)

##Opinion on Premarital Sex 
#Married vs Divorced vs Separated vs Other
tab <- as.data.frame(table(GSSnew$marital, GSSnew$premarsx))
colnames(tab) <- c("status", "premarital", "count")
pie_1a <- ggplot(tab, aes(status, premarital)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on premarital sex?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$premarsx))
colnames(tab) <- c("status", "premarital", "count")
pie_1b <- ggplot(tab, aes(status, premarital)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on premarital sex?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Opinion on Pornography Laws
tab <- as.data.frame(table(GSSnew$marital, GSSnew$pornlaw))
colnames(tab) <- c("status", "porn", "count")
pie_2a <- ggplot(tab, aes(status, porn)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on pornography regulation?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$pornlaw))
colnames(tab) <- c("status", "porn", "count")
pie_2b <- ggplot(tab, aes(status, porn)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on pornography regulation?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Opinion on Extramarital Sex 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$xmarsex))
colnames(tab) <- c("status", "exmar", "count")
pie_3a <- ggplot(tab, aes(status, exmar)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on extramarital sex?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$xmarsex))
colnames(tab) <- c("status", "exmar", "count")
pie_3b <- ggplot(tab, aes(status, exmar)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Opinion on extramarital sex?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Party Identification 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$partyid))
colnames(tab) <- c("status", "party", "count")
pie_4a <- ggplot(tab, aes(status, party)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Party identification?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$partyid))
colnames(tab) <- c("status", "party", "count")
pie_4b <- ggplot(tab, aes(status, party)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Party identification?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##How happy are you? 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$happy))
colnames(tab) <- c("status", "happy", "count")
pie_5a <- ggplot(tab, aes(status, happy)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("How happy are you?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$happy))
colnames(tab) <- c("status", "happy", "count")
pie_5b <- ggplot(tab, aes(status, happy)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("How happy are you?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Fundamentalism of Religion 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$fund))
colnames(tab) <- c("status", "fund", "count")
pie_6a <- ggplot(tab, aes(status, fund)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Fundamentalism of religion?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$fund))
colnames(tab) <- c("status", "fund", "count")
pie_6b <- ggplot(tab, aes(status, fund)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Fundamentalism of religion?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Self-Identified Class
tab <- as.data.frame(table(GSSnew$marital, GSSnew$class))
colnames(tab) <- c("status", "class", "count")
pie_7a <- ggplot(tab, aes(status, class)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Self-identified class?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$class))
colnames(tab) <- c("status", "class", "count")
pie_7b <- ggplot(tab, aes(status, class)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Self-identified class?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Work Status
tab <- as.data.frame(table(GSSnew$marital, GSSnew$wrkstat))
colnames(tab) <- c("status", "work", "count")
pie_8a <- ggplot(tab, aes(status, work)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Work status?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$wrkstat))
colnames(tab) <- c("status", "work", "count")
pie_8b <- ggplot(tab, aes(status, work)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Work status?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)


##Years of Education 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$educ))
colnames(tab) <- c("status", "edu", "count")
pie_9a <- ggplot(tab, aes(status, edu)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Years of education?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$educ))
colnames(tab) <- c("status", "edu", "count")
pie_9b <- ggplot(tab, aes(status, edu)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Years of education?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

      ###Histogram
        EducGraph2 <- ggplot(GSSnew, aes(x= educ,  group=marital2)) + 
            geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
            geom_text(aes( label = scales::percent(..prop..),
                           y= ..prop.. ), stat= "count", vjust = -.5) +
            labs(y = "Percent", fill="educ") +
            facet_grid(~marital2) +
            scale_y_continuous(labels = scales::percent)

##Children 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$childs))
colnames(tab) <- c("status", "child", "count")
pie_10a <- ggplot(tab, aes(status, child)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Children?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$childs))
colnames(tab) <- c("status", "child", "count")
pie_10b <- ggplot(tab, aes(status, child)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Children?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)


#Sex Education in Schools
tab <- as.data.frame(table(GSSnew$marital, GSSnew$sexeduc))
colnames(tab) <- c("status", "sexed", "count")
pie_11a <- ggplot(tab, aes(status, sexed)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Sex education in schools?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$sexeduc))
colnames(tab) <- c("status", "sexed", "count")
pie_11b <- ggplot(tab, aes(status, sexed)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Sex education in schools?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

       SexEducGraph2 <- ggplot(GSSnew, aes(x= sexeduc,  group=marital2)) + 
                  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
                  geom_text(aes( label = scales::percent(..prop..),
                                 y= ..prop.. ), stat= "count", vjust = -.5) +
                  labs(y = "Percent", fill="sexeduc") +
                  facet_grid(~marital2) +
                  scale_y_continuous(labels = scales::percent)

##Region 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$region))
colnames(tab) <- c("status", "region", "count")
pie_12a <- ggplot(tab, aes(status, region)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Region?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$region))
colnames(tab) <- c("status", "region", "count")
pie_12b <- ggplot(tab, aes(status, region)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Region?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

##Can people be trusted? 
tab <- as.data.frame(table(GSSnew$marital, GSSnew$trust))
colnames(tab) <- c("status", "trust", "count")
pie_13a <- ggplot(tab, aes(status, trust)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Can people be trusted?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$trust))
colnames(tab) <- c("status", "trust", "count")
pie_13b <- ggplot(tab, aes(status, trust)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Can people be trusted?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

      TrustGraph2 <- ggplot(GSSnew, aes(x= trust,  group=marital2)) + 
                        geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
                        geom_text(aes( label = scales::percent(..prop..),
                                       y= ..prop.. ), stat= "count", vjust = -.5) +
                        labs(y = "Percent", fill="trust") +
                        facet_grid(~marital2) +
                        scale_y_continuous(labels = scales::percent)

##Region at age 16
tab <- as.data.frame(table(GSSnew$marital, GSSnew$reg16))
colnames(tab) <- c("status", "region16", "count")
pie_20a <- ggplot(tab, aes(status, region16)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Region at age 16?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$reg16))
colnames(tab) <- c("status", "region16", "count")
pie_20b <- ggplot(tab, aes(status, region16)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Region at age 16?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)


##Live with both parents at age 16
tab <- as.data.frame(table(GSSnew$marital, GSSnew$family16))
colnames(tab) <- c("status", "family16", "count")
pie_21a <- ggplot(tab, aes(status, family16)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Live with both parents at age 16?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

tab <- as.data.frame(table(GSSnew$marital2, GSSnew$family16))
colnames(tab) <- c("status", "family16", "count")
pie_21b <- ggplot(tab, aes(status, family16)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("Live with both parents at age 16?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)


##If not with parents, why?
tab <- as.data.frame(table(GSSnew$marital, GSSnew$famdif16))
colnames(tab) <- c("status", "familyif16", "count")
pie_1 <- ggplot(tab, aes(status, familyif16)) + 
              geom_point(aes(size = count), colour = "green") + 
              theme_bw() + xlab("Marital Status?") + ylab("If not with both parents, why?") + scale_size_continuous(range=c(3,15)) + theme(plot.title = element_text(size = 10), legend.position="none")  + coord_fixed(ratio = 1)

        ParentsGraph2 <- ggplot(GSSnew, aes(x= famdif16,  group=marital2)) + 
                                geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
                                geom_text(aes( label = scales::percent(..prop..),
                                               y= ..prop.. ), stat= "count", vjust = -.5) +
                                labs(y = "Percent", fill="family") +
                                facet_grid(~marital2) +
                                scale_y_continuous(labels = scales::percent)

#### Experimenting with Plotting Relative Percentages 
GSSnew$class2 <- "blank"
GSSnew$class2 [GSSnew$class == "NO CLASS"] <- "NO CLASS"
GSSnew$class2 [GSSnew$class == "UPPER CLASS"] <- "UPPER CLASS"
GSSnew$class2 [GSSnew$class == "MIDDLE CLASS"] <- "MIDDLE CLASS"
GSSnew$class2 [GSSnew$class == "WORKING CLASS"] <- "WORKING CLASS"
GSSnew$class2 [GSSnew$class == "LOWER CLASS"] <- "LOWER CLASS"
GSSnew$class2 [is.na(GSSnew$class) ==T] <- NA

ClassGraph <- ggplot(GSSnew, aes(class2, group = marital2)) + 
          geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") + 
          scale_y_continuous(labels=scales::percent) +
          ylab("relative frequencies") +
          facet_grid(~marital2)

ClassGraphPerc <- ggplot(GSSnew, aes(x= class2,  group=marital2)) + 
    geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
    geom_text(aes( label = scales::percent(..prop..),
                   y= ..prop.. ), stat= "count", vjust = -.5) +
    labs(y = "Percent", fill="class2") +
    facet_grid(~marital2) +
    scale_y_continuous(labels = scales::percent)

ClassGraph2 <- ggplot(GSSnew, aes(x= class,  group=marital2)) + 
    geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
    geom_text(aes( label = scales::percent(..prop..),
                   y= ..prop.. ), stat= "count", vjust = -.5) +
    labs(y = "Percent", fill="class") +
    facet_grid(~marital2) +
    scale_y_continuous(labels = scales::percent)
## http://www.r-graph-gallery.com/48-grouped-barplot-with-ggplot2/
```

### Step Three: Split data by ballot and into train-validate-test groups

``` {r splits, include=FALSE, cache=TRUE }
## Separate GSSnew by ballot type A, B or C

GSS.A <- subset(GSSnew, (GSSnew$version==1|GSSnew$version==4))
clusters.vars.A <- c("year", "sexeduc", "region", "premarsx", "xmarsex", "partyid", "fund", "childs",  "degree", "Agecat1", "widowed", "wrkstat", "polviews", "happy", "class",  "reg16", "family16", "born", "parborn", "income", "sizecat", "attend", "relig16", "bible", "satjob", "satfin", "abnomore", "absingle", "divlaw", "marital2")
GSS.A <- GSS.A[,clusters.vars.A]
GSS.A <- GSS.A[complete.cases(GSS.A),]
GSS.B <- subset(GSSnew, (GSSnew$version==2|GSSnew$version==5))
GSS.C <- subset(GSSnew, (GSSnew$version==3|GSSnew$version==6))

## Train-validate-test split for GSS Ballot A
set.seed(567)
rand <- runif(nrow(GSS.A))

trainA <- GSS.A[rand>0.3,]
validA <- GSS.A[rand>0.15 & rand <0.3,]
testA <- GSS.A[rand<0.15,]

## Train-validate-test split for GSS Ballot B
set.seed(678)
rand <- runif(nrow(GSS.B))

trainB <- GSS.B[rand>0.3,]
validB <- GSS.B[rand>0.15 & rand <0.3,]
testB <- GSS.B[rand<0.15,]

## Train-validate-test split for GSS Ballot B
set.seed(789)
rand <- runif(nrow(GSS.C))

trainC <- GSS.C[rand>0.3,]
validC <- GSS.C[rand>0.15 & rand <0.3,]
testC <- GSS.C[rand<0.15,]
```


### Step Four: Analysis, logistic regression
``` {r logit, include=FALSE, cache=TRUE}
###Logistic Regression 
#glm(marital2 ~ <x>, data = <data>, family = binomial())
fitA <- glm(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + satjob + satfin + abnomore + absingle + divlaw, family=binomial(link='logit'),data=trainA) 
summary(fitA)
trainA$pred <- fitA$fitted.values
trainA$pred <- ifelse(trainA$pred > 0.5,1,0)
table(trainA$marital2, trainA$pred)
validA$pred <- predict(fitA, newdata = validA, type = "response")
validA$pred <- ifelse(validA$pred > 0.5,1,0)
table(validA$marital2, validA$pred)
fitA2 <- glm(marital2 ~ year + region + childs + degree + Agecat1 + widowed + wrkstat + class + income +  family16 + born + parborn + sizecat, family=binomial(link='logit'),data=trainA) 
trainA$pred2 <- fitA2$fitted.values
trainA$pred2 <- ifelse(trainA$pred2 > 0.5,1,0)
table(trainA$marital2, trainA$pred2)
validA$pred2 <- predict(fitA2, newdata = validA, type = "response")
validA$pred2 <- ifelse(validA$pred2 > 0.5,1,0)
table(validA$marital2, validA$pred2)


fitB <- glm(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + xmovie + divlaw + fefam, family=binomial(link='logit'),data=trainB) 
summary(fitB)

fitC <- glm(marital2 ~ year + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + xmovie + divlaw, family=binomial(link='logit'),data=trainB) 
summary(fitC)

#TrainA
fitA <- glm(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, family=binomial(link='logit'),data=trainA) 
#data = dfTraining, family = binomial())
summary(fitA)
#TrainB
fitB <- glm(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educ + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + divlaw + xmovie + fefam, family=binomial(link='logit'),data=trainB) 
summary(fitB)
#TrainC
fitC <- glm(marital2 ~ year + region + xmarsex + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educ + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle , family=binomial(link='logit'),data=trainC) 
summary(fitC)
#eliminated fefam b/c otherwise "algorithm did not converge -- fitted probabilities numerically 0 or 1 occurred"
#issues with marital2 being only 1 value --> create a factor variable rather than character (0 = married, 1 = divorced/split?)

```

# Step Five: Decision Trees, drop missing variables
``` {r trees}

###Decision Trees 
library(rpart)
#Ballot A
rtree_fitA <-rpart(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, data = trainA, method = 'class', cp = 0.00479512)
 printcp(rtree_fitA)
  library(rpart.plot)
rpart.plot(rtree_fitA, shadow.col="gray", nn=TRUE)

trainApred <- predict(rtree_fitA, trainA, type = 'class')
table(trainApred, trainA$marital2)
##Accuracy: (2626 + 407)/(2626 + 407 + 740 + 136)
###Accuracy: 77.59%

#Ballot B
rtree_fitB <-rpart(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educ + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + divlaw + xmovie + fefam, data = trainB, method = 'class', cp = 0.00519031)
printcp(rtree_fitB)
library(rpart.plot)
rpart.plot(rtree_fitB, shadow.col="gray", nn=TRUE)
trainBpred <- predict(rtree_fitB, trainB, type = 'class')
table(trainBpred, trainB$marital2)
##Accuracy: (2662 + 403)/(2662+403 + 753+159)
###Accuracy: 77.07%


#Ballot C
rtree_fitC <-rpart(marital2 ~ year + region + xmarsex + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educ + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + size + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainC, method = 'class', cp = 0.00604491)
printcp(rtree_fitC)
library(rpart.plot)
rpart.plot(rtree_fitC, shadow.col="gray", nn=TRUE)
trainCpred <- predict(rtree_fitC, trainC, type = 'class')
table(trainCpred, trainC$marital2)
##Accuracy: (2633 + 468)/(2633+468+690+210)
##Accuracy: 77.51%


##Source: https://www.r-bloggers.com/using-decision-trees-to-predict-infant-birth-weights/
####Decision trees: more error in predicting married (2/3), more accurate with predicting split (4/5)
```

# Step Six: Preparing for an Imputed Dataset: Creating GSSnew1, Collapsing Education, Size Variables; All Variables = Factor
```{r}
###Extra: New Dataset for KNN Imputation  
GSSnew1 <- GSSnew
str(GSSnew1)

###Collapsing: Education, Region -9,  childs -9, agecat1 -9, income -12, reg16 -10, size (factor, condense)

#Collapse: Education 
GSSnew1$educcat <-cut(GSSnew1$educ, seq(0,20,4))

#Collapse: Size - put into categories (8)
GSSnew1$sizecat <- NA
GSSnew1$sizecat [GSSnew1$size < 10] <- "rural"
GSSnew1$sizecat [GSSnew1$size >=10 & GSSnew1$size <= 99] <- "small"
GSSnew1$sizecat [GSSnew1$size >=100 & GSSnew1$size <= 999] <- "medium"
GSSnew1$sizecat [GSSnew1$size >=1000 & GSSnew1$size <= 9999] <- "large"
GSSnew1$sizecat <- factor(GSSnew1$sizecat)
str(GSSnew1$sizecat)

##Set each variable as a factor: size, educ, age, childs, agewed, year, id, sampcode, oversamp, formwt, wtssall, sampcode, version 

#Size
library (plyr) 
count(GSSnew1, 'sizecat')
GSSnew1$sizecat <- factor(GSSnew1$sizecat)
str(GSSnew1$sizecat)

#Educ 
count(GSSnew1, 'educ')
GSSnew1$educcat <-cut(GSSnew1$educ, seq(0,20,3))
GSSnew1$educcat <-factor(GSSnew1$educcat)
str(GSSnew1$educcat)
summary(GSSnew1$educcat)

#Age 
count(GSSnew1, 'age')
GSSnew1$age <-factor(GSSnew1$age)
str(GSSnew1$age)

#Childs
count(GSSnew1, 'childs')
GSSnew1$childs <-factor(GSSnew1$childs)
str(GSSnew1$childs)

#agewed
count(GSSnew1, 'agewed')
GSSnew1$agewed <-factor(GSSnew1$agewed)
str(GSSnew1$agewed)

#year 
count(GSSnew1, 'year')
GSSnew1$year <-factor(GSSnew1$year)
str(GSSnew1$year)

#id
count(GSSnew1, 'id')
GSSnew1$id <-factor(GSSnew1$id)
str(GSSnew1$id)

# sampcode
count(GSSnew1, 'sampcode')
GSSnew1$sampcode <-factor(GSSnew1$sampcode)
str(GSSnew1$sampcode)

#oversamp
count(GSSnew1, 'oversamp')
GSSnew1$oversamp <-factor(GSSnew1$oversamp)
str(GSSnew1$oversamp)

#formwt
count(GSSnew1, 'formwt')
GSSnew1$formwt <-factor(GSSnew1$formwt)
str(GSSnew1$formwt)

#wtssall 
count(GSSnew1, 'wtssall')
GSSnew1$wtssall <-factor(GSSnew1$wtssall)
str(GSSnew1$wtssall)

#version
count(GSSnew1, 'version')
GSSnew1$version <-factor(GSSnew1$version)
str(GSSnew1$version)

#class2
count(GSSnew1, 'class2')
GSSnew1$class2 <-factor(GSSnew1$class2)
str(GSSnew1$class2)

str(GSSnew1)
#Dimensions  
dim(GSSnew1)

```

#Step 7: Cutting up GSSnew1 and Imputing Ballots A, B and C

```{r}
#####Imputing - A, B, and C 
#install package and load library
###with Hmisc
library(Hmisc)

summary(GSS.A1)
GSS.A1 <- subset(GSSnew1, (GSSnew1$version==1|GSSnew1$version==4))
GSS.A1 <- subset(GSS.A1, select = c(marital2, year, sexeduc, educcat, region, premarsx, xmarsex, partyid, fund, childs, degree, Agecat1, widowed, wrkstat, polviews, happy, class, income, reg16, family16, born, parborn, sizecat, attend, relig16, bible, satfin, abnomore, absingle, divlaw, fefam))
str(GSS.A1)

###drop unused levels 
#sexeduc
count(GSS.A1, 'sexeduc')
GSS.A1$sexeduc <-factor(GSS.A1$sexeduc)
str(GSS.A1$sexeduc)

##Class
count(GSS.A1, 'class')
GSS.A1$class <-factor(GSS.A1$class)
str(GSS.A1$class)

##premarsx
count(GSS.A1, 'premarsx')
GSS.A1$premarsx <-factor(GSS.A1$premarsx)
str(GSS.A1$premarsx)

##xmarsex
count(GSS.A1, 'xmarsex')
GSS.A1$xmarsex <-factor(GSS.A1$xmarsex)
str(GSS.A1$xmarsex)

##size
count(GSS.A1, 'sizecat')
GSS.A1$sizecat <-factor(GSS.A1$sizecat)
str(GSS.A1$size)

#load data
data("GSS.A1")

#seed missing values ( 10% )
GSSA1.mis <- prodNA(GSS.A1, noNA = 0.1)
summary(GSSA1.mis)

###with DMwR - works? 
library(DMwR)
knnOutputA <- knnImputation(GSS.A1[, !names(GSS.A1) %in% "medv"])  # perform knn imputation.
anyNA(knnOutputA) 
summary(knnOutputA)


####B
GSS.B1 <- subset(GSSnew1, (GSSnew1$version==2|GSSnew1$version==5))
GSS.B1 <- subset(GSS.B1, select = c(marital2, year, educcat, sexeduc, premarsx, region, pornlaw, partyid, hapmar, fund, childs, degree, Agecat1, divorce, widowed, wrkstat, spwrksta, polviews, happy, trust, class, income, reg16, family16, born, parborn, sizecat, attend, relig16, bible, consci, helpful, fair, divlaw, xmovie, satfin, fefam))
summary(GSS.B1)
str(GSS.B1)

##factor variables: class, premarsx, sexeduc 

#class
count(GSS.B1, 'class')
GSS.B1$class <-factor(GSS.B1$class)
str(GSS.B1$class)

#premarsx 
count(GSS.B1, 'premarsx')
GSS.B1$premarsx <-factor(GSS.B1$premarsx)
str(GSS.B1$premarsx)

#sexeduc
count(GSS.B1, 'sexeduc')
GSS.B1$sexeduc <-factor(GSS.B1$sexeduc)
str(GSS.B1$sexeduc)

#load data
data("GSS.B1")

#seed missing values ( 10% )
GSSB1.mis <- prodNA(GSS.B1, noNA = 0.1)
summary(GSSB1.mis)

library(DMwR)
knnOutputB <- knnImputation(GSS.B1[, !names(GSS.B1) %in% "medv"])  # perform knn imputation.
anyNA(knnOutputB) 
summary(knnOutputB)


###C
#Impute data: Ballot C
GSS.C1 <- subset(GSSnew1, (GSSnew1$version==3|GSSnew1$version==6))
GSS.C1 <- subset(GSS.C1, select = c(marital2, year, educcat, region, pornlaw, partyid, hapmar, fund, childs, degree, Agecat1, divorce, widowed, wrkstat, spwrksta, polviews, happy, trust, class, income, reg16, family16, famdif16, born, parborn, sizecat, attend, relig16, helpful, fair, consci, satjob, satfin, abnomore, absingle, xmovie))
summary(GSS.C1)
#drop fefam b/c too many NAs and KNN wouldn't compute

#Factor: class
count(GSS.C1, 'class')
GSS.C1$class <-factor(GSS.C1$class)
str(GSS.C1$class)

library(DMwR)
knnOutputC <- knnImputation(GSS.C1[, !names(GSS.C1) %in% "medv"])  # perform knn imputation.
anyNA(knnOutputC) 
summary(knnOutputC)


``` 

#Step 8: Create Decision Trees Based off Imputed Values 
```{r}
##Try Decision Trees with Imputed Values and organized factors 

##Separate into train and test 
## Train-test split for GSS Ballot A
set.seed(567)
rand <- runif(nrow(knnOutputA))

trainAknn <- knnOutputA[rand>0.3,]
validAknn <- knnOutputA[rand>0.15 & rand <0.3,]
testAknn <- knnOutputA[rand<0.15,]

## Train-validate-test split for GSS Ballot B
set.seed(678)
rand <- runif(nrow(knnOutputB))

trainBknn <- knnOutputB[rand>0.3,]
validBknn <- knnOutputB[rand>0.15 & rand <0.3,]
testBknn <- knnOutputB[rand<0.15,]

## Train-validate-test split for GSS Ballot C
set.seed(789)
rand <- runif(nrow(knnOutputC))

trainCknn <- knnOutputC[rand>0.3,]
validCknn <- knnOutputC[rand>0.15 & rand <0.3,]
testCknn <- knnOutputC[rand<0.15,]

###Decision Trees 
library(rpart)
#Ballot A
rtree_fitAknn <-rpart(marital2 ~ year + sexeduc + + educcat + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, data = trainAknn, method = 'class', cp =  0.00435920)
 printcp(rtree_fitAknn)
  library(rpart.plot)
rpart.plot(rtree_fitAknn, shadow.col="gray", nn=TRUE)
trainApredknn <- predict(rtree_fitAknn, trainAknn, type = 'class')
table(trainApredknn, trainAknn$marital2)
##Accuracy: (2584 + 514)/(2584+514+633+178) = ###Accuracy: 79.25%
##Accuracy with collapsed levels: (2651+365)/(2651+365+111+782) = 77.15%


#Ballot B
rtree_fitBknn <-rpart(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam, data = trainBknn, method = 'class', cp =  0.00519031)
#cp = 0.00692042
printcp(rtree_fitBknn)
library(rpart.plot)
rpart.plot(rtree_fitBknn, shadow.col="gray", nn=TRUE)
trainBpredknn <- predict(rtree_fitBknn, trainBknn, type = 'class')
table(trainBpredknn, trainBknn$marital2)
##Accuracy: (2725+408)/(2725+408+748+96) = ###Accuracy: 78.8%
##Accuracy with collapsed levels: (2722 + 274)/(2722+274+882+99)= 75.33%


#Ballot C
rtree_fitCknn <-rpart(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainCknn, method = 'class', cp = 0.00388601)
printcp(rtree_fitCknn)
rpart.plot(rtree_fitCknn, shadow.col="gray", nn=TRUE)
trainCpredknn <- predict(rtree_fitCknn, trainCknn, type = 'class')
table(trainCpredknn, trainCknn$marital2)
##Accuracy: (2717+556)/(2717+556+602+126) = ##Accuracy: 82%
##Accuracy with collapsed levels: (2692+502)/(2692+502+151+656) = 79.83%
>>>>>>> refs/remotes/origin/Decision-Trees-


```

<<<<<<< HEAD
Original      | predicted marriage | predicted split
--------------|--------------------|----------------
married       | 1331               | 78
split         | 368                | 162

### Step Five: Analysis, decision trees
``` {r trees}
=======
>>>>>>> refs/remotes/origin/Decision-Trees-



#Step 10: Run Random Forest Based on Imputed Dataset 
```{r}
####Trying Random Forest with condensed variables 
 
######Train-Test
## Train-validate-test split for GSS Ballot A
set.seed(567)
rand <- runif(nrow(knnOutputA))

trainA1 <- knnOutputA[rand>0.3,]
validA1 <- knnOutputA[rand>0.15 & rand <0.3,]
testA1 <- knnOutputA[rand<0.15,]

library(randomForest)
forestA <- randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, data = trainA1)
summary(trainA1)
##Measuring error rate: 
forestA
## OOB estimate of  error rate: 24.51%
#Variable importance
  print(importance(forestA, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestA)
#Search for most optimal number of input features
  forestA.tune <- tuneRF(trainA1[,-1], trainA1$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
 
    ##lowest OOB error: mtry = 8 with an OOB error of 23.94% --> thus, 8 variables split = optimal

forestA.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam,data=trainA1, mtry=8, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testA1)
  
  forestA.tune
  ##Married: OOB estimate of error rate is 24.15%; married = 6.15% vs. split: 65.65%
  
  #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainA <- predict(forestA.tune, newdata = trainA1, type='prob')[,2]

#Predict values for test set
  pred.rf.testA <- predict(forestA, testA1, type='prob')[,2]

  #Set up ROC inputs
  input.rfA <- rbind(data.frame(model = "trainA", d = trainA1$marital2, m = pred.rf.trainA), 
                  data.frame(model = "testA", d = testA1$marital2,  m = pred.rf.testA))
  
#Graph all three ROCs
  roc.rfA <- ggplot(input.rfA, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainA")

#AUC
  calc_auc(roc.rfA)
  importance(forestA)
varImpPlot(forestA)
  
 
## Train-validate-test split for GSS Ballot B
set.seed(678)
rand <- runif(nrow(knnOutputB))

trainB1 <- knnOutputB[rand>0.3,]
validB1 <- knnOutputB[rand>0.15 & rand <0.3,]
testB1 <- knnOutputB[rand<0.15,]

library(randomForest)
forestB <- randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam, data = trainB1)
summary(trainB1)
##Measuring error rate: 
forestB
## OOB estimate of  error rate: 25.57%
  ##6.13% error rate with guessing married, 73% error rate with guessing split 

#Variable importance
  print(importance(forestB, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestB)
#Search for most optimal number of input features
  forestB.tune <- tuneRF(trainB1[,-1], trainB1$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
 
    ##lowest OOB error: mtry = 16 with an OOB error of 18.88% --> thus, 16 variables split = optimal

  forestB.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam,data=trainB1, mtry=16, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testB1)
  
  forestB.tune
  ##Married: OOB estimate of error rate is 25.19%; married = 7.37% vs. split: 68.69%
  
  forestB.param <- forestB.tune[forestB.tune[, 2] == min(forestB.tune[, 2]), 1]
  #incorrect # of dimensions? 
  
  #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainB <- predict(forestB.tune, newdata = trainB1, type='prob')[,2]

#Predict values for test set
  pred.rf.testB <- predict(forestB, testB1, type='prob')[,2]

  #Set up ROC inputs
  input.rfB <- rbind(data.frame(model = "trainB", d = trainB1$marital2, m = pred.rf.trainB), 
                  data.frame(model = "testB", d = testB1$marital2,  m = pred.rf.testB))
  
#Graph all three ROCs
  roc.rfB <- ggplot(input.rfB, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainB")

#AUC
  calc_auc(roc.rfB)
  importance(forestB)
varImpPlot(forestB)



## Train-validate-test split for GSS Ballot C
set.seed(789)
rand <- runif(nrow(knnOutputC))

trainC1 <- knnOutputC[rand>0.3,]
validC1 <- knnOutputC[rand>0.15 & rand <0.3,]
testC1 <- knnOutputC[rand<0.15,]

library(randomForest)
forestC <- randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainC1)
summary(trainC1)
##Measuring error rate: 
forestC
## OOB estimate of  error rate: 24.09%
  ##5.42% error rate with guessing married, 69.95% error rate with guessing split 

#Variable importance
  print(importance(forestC, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestC)
#Search for most optimal number of input features
  forestC.tune <- tuneRF(trainC1[,-1], trainC1$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
 
    ##lowest OOB error: mtry = 8 with an OOB error of 14.3% --> thus, 8 variables split = optimal

  forestC.tune <-randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle,data=trainC1, mtry=8, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testC1)
  
  forestC.tune
  ##Married: OOB estimate of error rate is 23.27%; married = 6.30% vs. split: 64.94%
  
  forestC.param <- forestC.tune[forestC.tune[, 2] == min(forestC.tune[, 2]), 1]
  #incorrect # of dimensions? 
  
  #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainC <- predict(forestC.tune, newdata = trainC1, type='prob')[,2]

#Predict values for test set
  pred.rf.testC <- predict(forestC, testC1, type='prob')[,2]

  #Set up ROC inputs
  input.rfC <- rbind(data.frame(model = "trainC", d = trainC1$marital2, m = pred.rf.trainC), 
                  data.frame(model = "testC", d = testC1$marital2,  m = pred.rf.testC))
  
#Graph all three ROCs
  roc.rfC <- ggplot(input.rfC, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainC")

#AUC
  calc_auc(roc.rfC)
  importance(forestC)
varImpPlot(forestC)
  
  
  
  
#Source: http://dataaspirant.com/2017/01/02/k-nearest-neighbor-classifier-implementation-r-scratch/ 
```

<<<<<<< HEAD
### Step Six: Analysis, clusters
```{r cluster setup, include=FALSE, cache = TRUE }
#using packages factoextra and NbClust and Cluster
library(factoextra)
library(NbClust)
library(cluster)

# set necessary variables for cluster analysis
clusters.train.a <- GSS.A[,clusters.vars.A]
clusters.train.a <- clusters.train.a[complete.cases(clusters.train.a),]

gss.a.mat <- model.matrix(~0 + year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + satjob + satfin + abnomore + absingle + divlaw, clusters.train.a)

# now with B ballot
clusters.vars.B <- c("year", "sexeduc", "region", "premarsx", "pornlaw", "partyid", "fund", "childs",  "degree", "Agecat1", "widowed", "wrkstat", "polviews", "happy", "trust", "class",  "reg16", "family16", "born", "parborn", "income", "sizecat", "attend", "relig16", "bible", "helpful", "fair", "consci", "satjob", "satfin", "xmovie", "fefam", "divlaw", "marital2")
clusters.b <- GSS.B[,clusters.vars.B]
clusters.b <- clusters.b[complete.cases(clusters.b),]

gss.b.mat <- model.matrix(~0 + year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + xmovie + divlaw + fefam, clusters.b)

# now with Ballot C
clusters.vars.C <- c("year", "region", "xmarsex", "pornlaw", "partyid", "fund", "childs",  "degree", "Agecat1", "widowed", "wrkstat", "polviews", "happy", "trust", "class", "reg16", "family16", "born", "parborn", "income", "fair", "helpful", "sizecat", "attend", "relig16", "bible", "consci", "satjob", "satfin", "abnomore", "absingle", "xmovie", "marital2")
clusters.c <- GSS.C[,clusters.vars.C]
clusters.c <- clusters.c[complete.cases(clusters.c),]

gss.c.mat <- model.matrix(~0 + year + region + xmarsex + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satjob + satfin + abnomore + absingle + xmovie, clusters.c)
```
``` {r cluster A, include=FALSE, cache=TRUE}
#determine optimal number of clusters using method within-cluster sum of squares
# visualize as line ("elbow" method)
elbow.a <- fviz_nbclust(gss.a.mat, kmeans, method = "wss") 
# (silhouette method)
sil.plot.a <- fviz_nbclust(gss.a.mat, kmeans, method = "silhouette") 
  # optimal cluster is 2! 
# compute kmeans clusters
km.a <- kmeans(gss.a.mat, 2, 10)
# compute hierarchical clusters and check silhouette for validation 
hc.a <- eclust(gss.a.mat, "hclust", k=2, method="ward.D2", graph=FALSE)
sil.a <- hc.a$silinfo
sil.a$clus.avg.widths
  # not very good  ~0.45
# compute PAM clusters
pam.a <- pam(gss.a.mat, 2)
# visulize as silhouette plot
fviz_silhouette(pam.a)
  # similar to hierarchical

#compare clusters to marital status
table(clusters.train.a$marital2, km.a$cluster)
table(clusters.train.a$marital2, hc.a$cluster)
table(clusters.train.a$marital2, pam.a$cluster)
```
```{r cluster output A, echo=FALSE, warning=FALSE, message=FALSE}
grid.arrange(elbow.a, sil.plot.a, ncol=2)
```
```{r cluster B and C, include=FALSE, cache=TRUE}
#determine optimal number of clusters using method within-cluster sum of squares
# visualize as line ("elbow" method)
elbow.b <- fviz_nbclust(gss.b.mat, kmeans, method = "wss") 
# (silhouette method)
sil.plot.b <- fviz_nbclust(gss.b.mat, kmeans, method = "silhouette") 
  # optimal cluster is 2! 
# compute kmeans clusters
km.b <- kmeans(gss.b.mat, 2, 10)
#ksil.a <- silhouette(km.a$cluster, dist(diss.a))
#head(ksil.a)
# compute hierarchical clusters and check silhouette for validation 
hc.b <- eclust(gss.b.mat, "hclust", k=2, method="complete", graph=FALSE)
sil.b <- hc.b$silinfo
sil.b$clus.avg.widths
  # not very good  ~0.47/~0.38

# compute PAM clusters
pam.b <- pam(gss.b.mat, 2)
# visulize as silhouette plot
fviz_silhouette(pam.b)
  # similar to hierarchical

#compare clusters to marital status
table(clusters.b$marital2, km.b$cluster)
table(clusters.b$marital2, hc.b$cluster)
table(clusters.b$marital2, pam.b$cluster)


#determine optimal number of clusters using method within-cluster sum of squares
# visualize as line ("elbow" method)
fviz_nbclust(gss.c.mat, kmeans, method = "wss") 
# (silhouette method)
fviz_nbclust(gss.c.mat, kmeans, method = "silhouette") 
  # optimal cluster is 2! 
# compute kmeans clusters
km.c <- kmeans(gss.c.mat, 2, 10)
#ksil.a <- silhouette(km.a$cluster, dist(diss.a))
#head(ksil.a)
# compute hierarchical clusters and check silhouette for validation 
hc.c <- eclust(gss.c.mat, "hclust", k=2, method="complete", graph=FALSE)
sil.c <- hc.c$silinfo
sil.c$clus.avg.widths
  # not very good  ~0.28/~0.41

# compute PAM clusters
pam.c <- pam(gss.c.mat, 2)
# visulize as silhouette plot
fviz_silhouette(pam.c)
  # similar to hierarchical

#compare clusters to marital status
table(clusters.b$marital2, km.b$cluster)
table(clusters.b$marital2, hc.b$cluster)
table(clusters.b$marital2, pam.b$cluster)
```
=======
#Step 11: Prepare Complete Datasets (Complete A, B, and C) 

```{r}
#Create complete dataset 
summary(GSSnew)
GSSnew2 <- GSSnew
str(GSSnew2)

###Collapsing: Education, Region -9,  childs -9, agecat1 -9, income -12, reg16 -10, size (factor, condense)

#Collapse: Education 
GSSnew2$educcat <-cut(GSSnew1$educ, seq(0,20,4))

#Collapse: Size - put into categories (8)
GSSnew2$sizecat <- NA
GSSnew2$sizecat [GSSnew2$size < 10] <- "rural"
GSSnew2$sizecat [GSSnew2$size >=10 & GSSnew2$size <= 99] <- "small"
GSSnew2$sizecat [GSSnew2$size >=100 & GSSnew2$size <= 999] <- "medium"
GSSnew2$sizecat [GSSnew2$size >=1000 & GSSnew2$size <= 9999] <- "large"
GSSnew2$sizecat <- factor(GSSnew2$sizecat)
str(GSSnew2$sizecat)

##Set each variable as a factor: size, educ, age, childs, agewed, year, id, sampcode, oversamp, formwt, wtssall, sampcode, version 

#Size
library (plyr) 
count(GSSnew2, 'sizecat')
GSSnew2$sizecat <- factor(GSSnew2$sizecat)
str(GSSnew2$sizecat)

#Educ 
count(GSSnew2, 'educ')
GSSnew2$educcat <-cut(GSSnew2$educ, seq(0,20,3))
GSSnew2$educcat <-factor(GSSnew2$educcat)
str(GSSnew2$educcat)
summary(GSSnew2$educcat)

#Age 
count(GSSnew2, 'age')
GSSnew2$age <-factor(GSSnew2$age)
str(GSSnew2$age)

#Childs
count(GSSnew2, 'childs')
GSSnew2$childs <-factor(GSSnew2$childs)
str(GSSnew2$childs)

#agewed
count(GSSnew2, 'agewed')
GSSnew2$agewed <-factor(GSSnew2$agewed)
str(GSSnew2$agewed)

#year 
count(GSSnew2, 'year')
GSSnew2$year <-factor(GSSnew2$year)
str(GSSnew2$year)

#id
count(GSSnew2, 'id')
GSSnew2$id <-factor(GSSnew2$id)
str(GSSnew2$id)

# sampcode
count(GSSnew2, 'sampcode')
GSSnew2$sampcode <-factor(GSSnew2$sampcode)
str(GSSnew2$sampcode)

#oversamp
count(GSSnew2, 'oversamp')
GSSnew2$oversamp <-factor(GSSnew2$oversamp)
str(GSSnew2$oversamp)

#formwt
count(GSSnew2, 'formwt')
GSSnew2$formwt <-factor(GSSnew2$formwt)
str(GSSnew2$formwt)

#wtssall 
count(GSSnew2, 'wtssall')
GSSnew2$wtssall <-factor(GSSnew2$wtssall)
str(GSSnew2$wtssall)

#version
count(GSSnew2, 'version')
GSSnew2$version <-factor(GSSnew2$version)
str(GSSnew2$version)

#class2
count(GSSnew2, 'class2')
GSSnew2$class2 <-factor(GSSnew2$class2)
str(GSSnew2$class2)

str(GSSnew2)
#Dimensions  
dim(GSSnew2)

#Ballot A
GSS.A1.complete <- subset(GSSnew2, (GSSnew2$version==1|GSSnew2$version==4))
GSS.A1.complete <- subset(GSS.A1.complete, select = c(marital2, year, sexeduc, educcat, region, premarsx, xmarsex, partyid, fund, childs, degree, Agecat1, widowed, wrkstat, polviews, happy, class, income, reg16, family16, born, parborn, sizecat, attend, relig16, bible, satfin, abnomore, absingle, divlaw, fefam))
str(GSS.A1.complete)

##Only complete cases 
GSS.A1.complete <- GSS.A1.complete[complete.cases(GSS.A1.complete),] #assign to a new data.frame
summary(GSS.A1.complete)
str(GSS.A1.complete)


###drop unused levels 
#sexeduc
count(GSS.A1.complete, 'sexeduc')
GSS.A1.complete$sexeduc <-factor(GSS.A1.complete$sexeduc)
str(GSS.A1.complete$sexeduc)

##Class
count(GSS.A1.complete, 'class')
GSS.A1.complete$class <-factor(GSS.A1.complete$class)
str(GSS.A1.complete$class)

##premarsx
count(GSS.A1.complete, 'premarsx')
GSS.A1.complete$premarsx <-factor(GSS.A1.complete$premarsx)
str(GSS.A1.complete$premarsx)

##xmarsex
count(GSS.A1.complete, 'xmarsex')
GSS.A1.complete$xmarsex <-factor(GSS.A1.complete$xmarsex)
str(GSS.A1.complete$xmarsex)

##size
count(GSS.A1.complete, 'sizecat')
GSS.A1.complete$sizecat <-factor(GSS.A1.complete$sizecat)
str(GSS.A1.complete$size)

####B
GSS.B1.complete <- subset(GSSnew2, (GSSnew2$version==2|GSSnew2$version==5))
GSS.B1.complete <- subset(GSS.B1.complete, select = c(marital2, year, educcat, sexeduc, premarsx, region, pornlaw, partyid, fund, childs, degree, Agecat1, widowed, wrkstat, polviews, happy, trust, class, income, reg16, family16, born, parborn, sizecat, attend, relig16, bible, divlaw, xmovie, satfin, helpful, fair, satjob, consci, fefam))
#deleted hapmar, divorce, spwrksta,hapmar

summary(GSS.B1.complete)
str(GSS.B1.complete)
summary(GSS.B1.complete$marital2)


##Only complete cases 
GSS.B1.complete <- GSS.B1.complete[complete.cases(GSS.B1.complete),] #assign to a new data.frame
summary(GSS.B1.complete)
str(GSS.B1.complete)
summary(GSS.B1.complete$marital2)

##factor variables: class, premarsx, sexeduc 

#class
count(GSS.B1.complete, 'class')
GSS.B1$class.complete <-factor(GSS.B1$class)
str(GSS.B1$class.complete)

#premarsx 
count(GSS.B1.complete, 'premarsx')
GSS.B1.complete$premarsx <-factor(GSS.B1.complete$premarsx)
str(GSS.B1.complete$premarsx)

#sexeduc
count(GSS.B1.complete, 'sexeduc')
GSS.B1.complete$sexeduc <-factor(GSS.B1.complete$sexeduc)
str(GSS.B1.complete$sexeduc)

###C 
GSS.C1.complete <- subset(GSSnew2, (GSSnew2$version==3|GSSnew2$version==6))
GSS.C1.complete <- subset(GSS.C1.complete, select = c(marital2, year, educcat, region, pornlaw, partyid, fund, childs, degree, Agecat1,  widowed, wrkstat, polviews, happy, trust, class, income, reg16, family16, famdif16, born, parborn, sizecat, attend, relig16, helpful, fair, consci, satjob, satfin, abnomore, absingle, xmovie))
summary(GSS.C1.complete$marital2)
#drop fefam b/c too many NAs and KNN wouldn't compute
#drop - spwrksta, divorce,hapmar

##Only complete cases 
GSS.C1.complete <- GSS.C1.complete[complete.cases(GSS.C1.complete),] #assign to a new data.frame
summary(GSS.C1.complete$marital2)


#Factor: class
count(GSS.C1.complete, 'class')
GSS.C1.complete$class <-factor(GSS.C1.complete$class)
str(GSS.C1.complete$class)
 


```

#Step 12: Random Forest on Complete

```{r}
######Train-Test
## Train-validate-test split for GSS Ballot A
set.seed(567)
rand <- runif(nrow(GSS.A1.complete))

trainA1complete <- GSS.A1.complete[rand>0.3,]
validA1complete <- GSS.A1.complete[rand>0.15 & rand <0.3,]
testA1complete <- GSS.A1.complete[rand<0.15,]

library(randomForest)
forestAcomplete <- randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, data = trainA1complete)
summary(trainA1complete)
##Measuring error rate: 
forestAcomplete
## OOB estimate of  error rate: 24.51%
#Variable importance
  print(importance(forestAcomplete, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestAcomplete)
#Search for most optimal number of input features
  forestAcomplete.tune <- tuneRF(trainA1complete[,-1], trainA1complete$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
  ##lowest OOB error: mtry = 4 with an OOB error of 24.99% --> thus, 4 variables split = optimal

forestAcomplete.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam,data=trainA1complete, mtry=4, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=validA1complete)
  
  forestAcomplete.tune
  #OOB estimate of error rate is 25.21%; married = 6.39% vs. split: 68.34%
  
  #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainAcomplete <- predict(forestAcomplete.tune, newdata = trainA1complete, type='prob')[,2]

#Predict values for validating set (or test?)
  pred.rf.validAcomplete <- predict(forestAcomplete, validA1complete, type='prob')[,2]

  #Set up ROC inputs
  input.rfAcomplete <- rbind(data.frame(model = "trainAcomplete", d = trainA1complete$marital2, m = pred.rf.trainAcomplete), 
                  data.frame(model = "validAcomplete", d = validA1complete$marital2,  m = pred.rf.validAcomplete))
  ##(used to be test)
  
#Graph all three ROCs
  roc.rfAcomplete <- ggplot(input.rfAcomplete, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainAcomplete")

#AUC
  calc_auc(roc.rfAcomplete)
  importance(forestAcomplete)
varImpPlot(forestAcomplete)
  
################################################# 
## Train-validate-test split for GSS Ballot B
set.seed(678)
rand <- runif(nrow(GSS.B1.complete))
trainB1complete <- GSS.B1.complete[rand>0.3,]
validB1complete <- GSS.B1.complete[rand>0.15 & rand <0.3,]
testB1complete <- GSS.B1.complete[rand<0.15,]

library(randomForest)
forestBcomplete <- randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam, data = trainB1complete)
summary(trainB1complete)
##Measuring error rate: 
forestBcomplete
## OOB estimate of  error rate: 26.85%
  ##6.23% error rate with guessing married, 72.6% error rate with guessing split 

#Variable importance
  print(importance(forestBcomplete, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestBcomplete)
#Search for most optimal number of input features
  forestBcomplete.tune <- tuneRF(trainB1complete[,-1], trainB1complete$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
 
    ##lowest OOB error: mtry = 16 with an OOB error of 25.74% --> thus, 16 variables split = optimal

  forestBcomplete.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam,data=trainB1complete, mtry=16, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=validB1complete) #valid instead of test group
  
  forestBcomplete.tune
  ##OOB estimate of error rate is 27.01%; married = 8.92% vs. split: 67.12%
  
   #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainBcomplete <- predict(forestBcomplete.tune, newdata = trainB1complete, type='prob')[,2]

#Predict values for test set (or validating set?)
  pred.rf.validBcomplete <- predict(forestBcomplete, validB1complete, type='prob')[,2]

  #Set up ROC inputs
  input.rfBcomplete <- rbind(data.frame(model = "trainB", d = trainB1complete$marital2, m = pred.rf.trainBcomplete), 
                  data.frame(model = "validB", d = validB1complete$marital2,  m = pred.rf.validBcomplete))
  
#Graph all three ROCs
  roc.rfBcomplete <- ggplot(input.rfBcomplete, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainB")

#AUC
  calc_auc(roc.rfBcomplete)
  importance(forestBcomplete)
varImpPlot(forestBcomplete)



## Train-validate-test split for GSS Ballot C
set.seed(789)
rand <- runif(nrow(GSS.C1.complete))
trainC1complete <- GSS.C1.complete[rand>0.3,]
validC1complete <- GSS.C1.complete[rand>0.15 & rand <0.3,]
testC1complete <- GSS.C1.complete[rand<0.15,]


library(randomForest)
forestCcomplete <- randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainC1complete)
summary(trainC1complete)

##Measuring error rate: 
forestCcomplete
## OOB estimate of  error rate: 30.04%
##9.82% error rate with guessing married, 67.78% error rate with guessing split 

#Variable importance
  print(importance(forestCcomplete, type = 2))
  #Most important variables: year, sex ed, region, premarsx, xmarsex, partyid, fundamentalism, children#, 
    #degree, age ...etc. 
 plot(forestCcomplete)
#Search for most optimal number of input features
  forestCcomplete.tune <- tuneRF(trainC1complete[,-1], trainC1complete$marital2, ntreeTry = 500, 
                     mtryStart = 1, stepFactor = 2, 
                     improve = 0.001, trace = TRUE, plot = TRUE)
 
    ##lowest OOB error: mtry = 4 with an OOB error of 28.1% --> thus, 4 variables split = optimal

  forestCcomplete.tune <-randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle,data=trainC1complete, mtry=4, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=validC1complete)
  
  forestCcomplete.tune
  ##OOB estimate of error rate is 29.84%; married = 8.63% vs. split: 69.44%
  
  #plotROC
  library(plotROC)

  #Predict values for train set
  pred.rf.trainCcomplete <- predict(forestCcomplete.tune, newdata = trainC1complete, type='prob')[,2]

#Predict values for test set
  pred.rf.validCcomplete <- predict(forestCcomplete, validC1complete, type='prob')[,2]

  #Set up ROC inputs
  input.rfCcomplete <- rbind(data.frame(model = "trainCcomplete", d = trainC1complete$marital2, m = pred.rf.trainCcomplete), 
                  data.frame(model = "validC", d = validC1complete$marital2,  m = pred.rf.validCcomplete))
  
#Graph all three ROCs
  roc.rfCcomplete <- ggplot(input.rfC, aes(d = d, model = model, m = m, colour = model)) + 
             geom_roc(show.legend = TRUE) + style_roc()  +ggtitle("TrainCcomplete")

#AUC
  calc_auc(roc.rfCcomplete)
  importance(forestCcomplete)
varImpPlot(forestCcomplete)
  
```



#Step 12: Complete on Complete (use test) Random Forest on Complete Dataset 

```{r}

##Complete on Complete (use 'test' rather than 'validate')
## Train-validate-test split for GSS Ballot A

forestAcomplete.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam,data=trainA1complete, mtry=4, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testA1complete)
   forestAcomplete.tune
######OOB estimate of error rate is 25.17%; married = 6.52% vs. split: 67.9%
 
##Complete on Complete 
## test for GSS Ballot B

  forestBcomplete.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam,data=trainB1complete, mtry=16, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testB1complete)  #test group
  
  forestBcomplete.tune
  ##OOB estimate of error rate is 26.17%; married = 8.2% vs. split: 65.93%
  
 
#######Ballot C
  forestCcomplete.tune <-randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle,data=trainC1complete, mtry=4, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testC1complete)
  
  forestCcomplete.tune
  ##OOB estimate of error rate is 29.84%; married = 8.63% vs. split: 69.44%
  

```



#Step 13: Imputed on Complete, Compare results to Complete on Complete
```{r}

##Imputed on Complete
library(randomForest)

###BallotA
forestAimponcomp.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + educcat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam,data=trainA1, mtry=8, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testA1complete)
  forestAimponcomp.tune
###Trained on imputed dataset, tested on complete dataset
  ##OOB estimate of error rate is 23.97%; married = 7.2% vs. split: 64.3%
  ##Imputed (train on imputed trainA1 and tested on testA1complete) is more accurate for Ballot A

###BallotB
forestBimponcomp.tune <-randomForest(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam,data=trainB1, mtry=16, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testB1complete)  #test group
  forestBimponcomp.tune
 ##OOBestimate of error rate is 25.4%; married = 7.62% vs. split: 68.77%
  ##Imputed is more accurate overall for Ballot B, but for split category specifically, the forestBcomplete.tune is more accurate (than imputed) for Ballot B
  
###BallotC 
   forestCimponcomp.tune <-randomForest(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle,data=trainC1, mtry=4, ntree=500, 
     keep.forest=TRUE, importance=TRUE,test=testC1complete)
     forestCimponcomp.tune
  
     ##OOB  estimate of error rate: 23.92%: married = 4.78%; split: 70.9%
     ##Imputed is more accurate overall for Ballot C,but for the split category speficifically, training on the complete (forestCcomplete.tune) is more accurate 
   
```


#Step 14: Decision Trees: Which one is best? 
```{r}
#Decision tree model: already dropped missing so orig is from complete, just did imputed 
#now test both on complete dataset 

library(rpart)
#Ballot A
###Complete on Complete  
    rtree_fitAcc <-rpart(marital2 ~ year + sexeduc + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + satfin + + educcat + abnomore + absingle + divlaw + fefam, data = trainA1complete, method = 'class', cp = 0.00739645)
     printcp(rtree_fitAcc)
      library(rpart.plot)
    rpart.plot(rtree_fitAcc, shadow.col="gray", nn=TRUE)
    
    trainApredcc <- predict(rtree_fitAcc, testA1complete, type = 'class')
    table(trainApredcc, testA1complete$marital2)
    ##Overall Accuracy: (337+43)/(337+43+89+24)= 77.08%
    ##Married accuracy: 337/(337+89) = 79.12%
    ##Split accuracy:  43/(24+43) = 64.18%

##Imputed on Complete
  rtree_fitAknn <-rpart(marital2 ~ year + sexeduc + + educcat + region + premarsx + xmarsex + partyid + fund + childs + degree + Agecat1 + widowed + wrkstat + polviews + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + satfin + abnomore + absingle + divlaw + fefam, data = trainAknn, method = 'class', cp =  0.00435920)
     printcp(rtree_fitAknn)
      library(rpart.plot)
    rpart.plot(rtree_fitAknn, shadow.col="gray", nn=TRUE)
    trainApredknnonc <- predict(rtree_fitAknn, testA1complete, type = 'class')
    table(trainApredknnonc, testA1complete$marital2)
    ##Accuracy: (341+35)/(341+35+97+20) =  76.27%
    ##Married accuracy: 341/(341+97) = 77.85%
    ##Split accuracy:  35/55 = 63.64%
    
############################
#Ballot B
#Complete on Complete        
    rtree_fitBcc <-rpart(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam, data = trainB1complete, method = 'class', cp =  0.00681431)
    printcp(rtree_fitBcc)
    library(rpart.plot)
    rpart.plot(rtree_fitBcc, shadow.col="gray", nn=TRUE)
    trainBpredcc <- predict(rtree_fitBcc, testB1complete, type = 'class')
    table(trainBpredcc, testB1complete$marital2)
    ##Overall Accuracy:  (249+33)/(249+86+33+31)= 70.68%
    ##Married accuracy:  249/(249+86)= 74.33
    ##Split accuracy:   33/(31+33) = 51.56%

##Imputed on Complete
  rtree_fitBknn <-rpart(marital2 ~ year + sexeduc + region + premarsx + pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + happy + trust + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + bible + helpful + fair + consci + satfin + divlaw + xmovie + fefam, data = trainB1, method = 'class', cp =  0.00201845)
     printcp(rtree_fitBknn)
      library(rpart.plot)
    rpart.plot(rtree_fitBknn, shadow.col="gray", nn=TRUE)
    trainBpredknnonc <- predict(rtree_fitBknn, testB1complete, type = 'class')
    table(trainBpredknnonc, testB1complete$marital2)
    ##Accuracy: (258+51)/(258+51+68+22) =  77.44%
    ##Married accuracy: 258/(258+68) = 79.14%
    ##Split accuracy:  51/(22+51) = 69.86%
    
#Ballot C    

  #Complete on Complete        
    rtree_fitCcc <-rpart(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainC1complete, method = 'class', cp =  0.00681431)
    printcp(rtree_fitCcc)
    library(rpart.plot)
    rpart.plot(rtree_fitCcc, shadow.col="gray", nn=TRUE)
    trainCpredcc <- predict(rtree_fitCcc, testC1complete, type = 'class')
    table(trainCpredcc, testC1complete$marital2)
    ##Accuracy: (58+11)/(58+11+28+16)= 61.06%
    ##Married accuracy:58/(58+28)= 67.44%
    ##Split accuracy:  11/(11+16)= 40.74%
    
    
#Imputed on Complete
rtree_fitCknn <-rpart(marital2 ~ year + region +  pornlaw + partyid + fund + childs + degree + Agecat1 + widowed + educcat + wrkstat + polviews + trust + happy + class + income + reg16 + family16 + born + parborn + sizecat + attend + relig16 + helpful + fair + consci + satjob + satfin + abnomore + absingle, data = trainCknn, method = 'class', cp =  0.00435920)
     printcp(rtree_fitCknn)
      library(rpart.plot)
    rpart.plot(rtree_fitCknn, shadow.col="gray", nn=TRUE)
    trainCpredknn <- predict(rtree_fitCknn, testC1complete, type = 'class')
    table(trainCpredknn, testC1complete$marital2)
  ##Accuracy: (68+18)/(68+21+6+18)=76.11%
    ##Married accuracy:68/(68+21)=76.40%
    ##Split accuracy:  18/24=75%
 
    
```
>>>>>>> refs/remotes/origin/Decision-Trees-
